<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <style>
    .container {
      position: relative;
      width: 100%;
      overflow: hidden;
      padding-top: 100%;
      /* 1:1 Aspect Ratio */
    }

    .responsive-iframe {
      position: absolute;
      top: 0;
      left: 0;
      bottom: 0;
      right: 0;
      width: 100%;
      height: 100%;
      border: none;
    }
  </style>
  <title> immaterial.cloud: Using peer-to-peer technologies for music</title>
  <link href="big.css" rel="stylesheet" type="text/css" />
  <link href="themes/dsu.css" rel="stylesheet" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/default.min.css" />
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js"></script>
  <script src="big.js"></script>
  <script>
    hljs.initHighlightingOnLoad();
  </script>
  <style>
    .hljs {
      overflow-x: initial;
    }
  </style>
  <script src="js/index-citations-global.js"></script>

  <script>
    function run() {
      hljs.initHighlightingOnLoad();

      IndexCitations({
        referenceId: "#citations",
      });

      const citations = document.querySelectorAll(".citationLink");
      // TODO: update this to be the last slide whenever you make it
      citations.forEach((citation) => (citation.href = "#16"));

      const ref = document.querySelectorAll("#citations cite");

      ref.forEach((reference) => {
        var el = document.createElement("span");
        el.innerHTML = '<a href="javascript:history.back()">&#8627;</a>';
        insertAfter(reference, el);
      });
    }

    if (document.readyState != "loading") {
      run();
    } else {
      document.addEventListener("DOMContentLoaded", run);
    }

    function insertAfter(referenceNode, newNode) {
      referenceNode.parentNode.insertBefore(
        newNode,
        referenceNode.nextSibling
      );
    }
  </script>
  <script src="big.js"></script>
  <script src="js/lazysizes.min.js"></script>
</head>

<body>
  <div>
    <div>
      immaterial.cloud </br>
      Using peer-to-peer technologies for music
    </div>
    <div>
      <em> Tate Carson </em>
    </div>
    <notes>immaterial.cloud is an immersive audiovisual installation that explores a possible networked future of
      peer-to-peer technologies, away from cloud computing. Participants experience the work via two to four
      smartphones placed in different locations in a room. As participants walk up to a phone, they see a representation
      of themselves through data. If the participant gets close enough, the phone triggers a change in the sound of
      immaterial.cloud and the other phones follow.</notes>
  </div>
  <div>

    <img src="images/immaterialcloud1.jpg"><img>
    <notes>
      The idea for immaterial.cloud emerged to create a communal experience during the COVID-19 shelter-in-place
      orders during which many people have turned to the internet for communication and entertainment. While social
      networks such as Facebook or Google seek our attention for profit, immaterial.cloud seeks a deep attention that
      creates a shared sense of place and time for the participants.
    </notes>
  </div>
  <div>
    <img src="images/p2p.webp" alt="credit: rand corporation" />

    <notes>
      immaterial.cloud is a web application that uses peer-to-peer technologies to send data between phones without the
      need for an intermediary server similar to the decentralized or distributed part of this rand corp diagram.
      immaterial.cloud creates the chance for a shared space with participants by using technology collectively. It
      requires the phones to act together, not as individuals as is usual in this era of personalized devices.
      Experiencing
      immaterial.cloud presents an opportunity for a restoration of attention fatigued by an overuse of technology.
    </notes>
  </div>
  <div>
    Attention Economy
    <cite>
      Sarah Hartman-Caverly. Human nature is not a machine: On liberty, attention engineering, and learning analytics.
      Library Trends, 68(1):24–53, 2019.
    </cite>
    <cite>
      Josef Falkinger. Attention economies. Journal of Economic Theory, 133(1):266–294, 2007.
    </cite>
    <cite>
      T. Wu. The Attention Merchants: The Epic Scramble to Get Inside Our Heads. Vintage Books, 2017.
    </cite>
    <cite>
      N Katherine Hayles. Hyper and deep attention: The generational divide in cognitive modes. Profession, pages
      187–199, 2007.
    </cite>
    <notes>
      Why peer-to-peer? Because of the attention economy, which turns our attention into an economic good by measuring
      it through clicks, downloads, and likes. Measurement allows companies to sell our attention as data to
      advertisers.
    </notes>
  </div>
  <div>
    <img src="images/google-search.png"></img>

    <notes>
      An example of the attention economy would be Google Search. Here's a
      recent search where Google predicted search results based on my browsing history on Google Books then
      automatically made available to Google Search, allowing the prediction to happen. The perniciousness of this is
      that this prediction is a useful tool, and most users won’t take the time to stop and analyze how it works. They
      will just enjoy the ease of use that data sharing has given them, without thinking about the consequences in loss
      of privacy.
    </notes>
  </div>

  <div class="nowrap">
    Alternatives?
    <cite>
      J. Odell. How to Do Nothing: Resisting the Attention Economy. Melville House, Brooklyn, London, 2019.
    </cite>
    <notes>
      How can the attention economy be resisted? We must re- design the technologies that encourage a capitalist percep-
      tion of time, place, self, and community. Deepening one’s concept of place will extend an awareness of history and
      cur- rent connection to everything around them. Odell suggests that “doing nothing” moves our attention from
      economic concerns to the physical, place based domain [18]. Doing nothing, or sitting out the attention economy is
      an active proposition and “entails an active process of listening that seeks out the effects of racial,
      environmental, and economic injustice and brings about real change [18].”

      Because of these platforms’ flaws we shouldn’t be using them to distribute and make our art. These platforms re-
      ward a way of being that isn’t beneficial to society. They resist the concept of interconnection, by emphasizing
      our differences and not allowing us to show fuller versions of ourselves. We must “stand apart” as Odell
      suggests, and create new systems for communication on the internet. Distribued peer-to-peer systems can be a part
      of this.
    </notes>
  </div>

  <div>
    Background
  </div>
  <!-- <div>
    <div>Audience as a speaker array
      <cite>B. Taylor. A History of the Audience as a Speaker Array. In Proceedings of the International Conference on
        New Interfaces for Musical Expression, volume 481-486, Aalborg University Copenhagen, Denmark, 2017.</cite>
    </div>

    <ul>
      <li>Soundworks
        <cite>S. Robaszkiewicz and N. Schnell. Soundworks–A playground for artists and developers to create
          collaborative mobile web performances. In WAC-1st Web Audio Conference, 2015.</cite>
      </li>
      <li>Nexus
        <cite>
          J. Allison, Y. Oh, and B. Taylor. NEXUS: Collaborative Performance for the Masses, Handling Instrument
          Interface Distribution Through the Web. In Proceedings of the International Conference on New Interfaces for
          Musical Expression (NIME), pages 1–6, 2013.
        </cite>
      </li>
      <li>massMobile
        <cite>
          N. Weitzner, J. Freeman, Y.-L. Chen, and S. Garrett. massMobile: Towards a flexible framework for large-scale
          participatory collaborations in live performances. Organised Sound, 18(1):30–42, 2013.
        </cite>
      </li>
      <li>Rhizome
        <cite>T. Shaw, S. Piquemal, and J. Bowers. Fields: An Exploration into the use of Mobile Devices as a Medium for
          Sound Diffusion. In Proceedings of the International Conference on New Interfaces for Musical Expression,
          pages 281–284, Baton Rouge, Louisiana, 2015.</cite>
      </li>
    </ul>
    <notes>
      mmaterial.cloud uses the audience as a speaker array, a practice with a long history in music [28]. Many
      frameworks and compositions use distributed smartphone speaker sys- tems with the Web Audio API. Frameworks such
      as Schnell and Robaszkiewicz’s Soundworks [22], Jesse Allison’s Nexus [1], Weitzner and Freeman’s massMobile [30]
      and Piquemal’s Rhizome [25] are designed for artists who don’t want to cre- ate bespoke systems. These frameworks
      run on a variety of centralized server configurations, anywhere that Node.js can run. These systems have taken a
      variety of networking approaches that center on cloud computing, whether run- ning a cloud-based virtual machine
      (VM) such as Amazon’s EC2 or Google Cloud [2], a “serverless” host like Zeit’s Vercel (formerly known as Now) [5],
      a Platform as a Service

      (PaaS) [7] such as PubNub, or server running on one’s own laptop [14]. Many papers don’t describe projects’
      hosting configurations, but because of the frameworks used, one can assume that they run on some ver- sion of the
      aforementioned technology [25, 8, 13, 26]. The lack of information about hosting configurations often leaves room
      for inquiry. What these systems have in common is that they use centralized networking topology.
    </notes>
  </div> -->
  <div>
    <img src="images/napster-2.jpg" alt="Spencer Platt/Newsmakers/Getty">
    <notes>
      Peer-to-peer systems aren’t new but had their heyday in the public imagination during the height of online file
      sharing when Napster was operating between 1999 and 2001.
    </notes>
  </div>
  <div>
    <div>Early p2p music projects</div>
    <ul>
      <li>Tanaka mobile music system with PDAs
        <cite>
          A. Tanaka. Mobile music making. In Proceedings of the 2004 conference on New interfaces for musical
          expression, pages 154–156, 2004.
        </cite>
      </li>
      <li>
        Lee, Essl, and Mao - MANET
        <cite>
          S. W. Lee, G. Essl, and Z. M. Mao. Distributing Mobile Music Applications for Audience Participation Using
          Mobile Ad-hoc Network (MANET). In NIME, pages 533–536, 2014.
        </cite>
      </li>
    </ul>
    <notes>
      Because of the popularity and common knowledge of
      those systems, interactive music works began to emerge that used and extended similar technologies. In 2004 Atau
      Tanaka
      created a collaborative music-making system based on personal digital assistants (PDAs), which extend the simple
      sharing of music on peer-to-peer systems allowing users who were near each other to interact through Service
      Discovery Protocol (SDP). Lee, Essl, and Mao have used SDP effectively to distribute applications to mobile
      phones in a mobile ad hoc network (MANET).
    </notes>
  </div>
  <div>
    <div>
      WebRTC systems
    </div>
    <ul>
      <li>Soundtrap
        <cite>F. Lind and A. MacPherson. Soundtrap: A collaborative music studio with Web Audio. London, UK,
          2017.</cite>
      </li>
      <li>GroupLoop
        <cite>
          D. B. Ramsay and J. A. Paradiso. Grouploop: A collaborative, network-enabled audio feedback instrument. In New
          Interfaces for Musical Expression, pages 251–254, Baton Rouge, Louisiana, 2015.
        </cite>
      </li>
      <li>Hear-Here
        <cite>
          A. Black. Hear-Here: A choreographed peer-to-peer network for live participation on the radio. In Proceedings
          of the 12th International Audio Mostly Conference on Augmented and Participatory Sound and Music Experiences,
          pages 1–6, London, UK, 2017.
        </cite>
      </li>
      <li>Fun With Chords
        <cite>
          L. Xing, M. Ulrich, and O. Diab. Fun With Chords–A Distributed Music Player.
        </cite>
      </li>
    </ul>

    <notes>
      Several web audio projects have used WebRTC. Lind’s Soundtrap uses WebRTC’s video channel. Ramsay and
      Paradiso’s Grouploop uses the audio channel to send audio between clients to create a feedback based performance
      system, and Black’s Hear-Here uses it to coordinate an FM radio broadcast out of the audio of
      distributed clients. Xing, Ulrich and Diab’s Fun With Chords, a distributed music player, uses the data
      channel. Authors gave few reasons for choosing WebRTC over other methods in the cited papers, but one can assume
      they chose WebRTC for the reasons same that interest me—the minimal need for servers.
    </notes>
  </div>

  <div>
    How does immaterial.cloud use WebRTC?

    <notes>
      immaterial.cloud is networked using WebRTC (Web Real-Time Communication), which allows for websites to stream
      audio, video, or data between each other without an intermediary.

      immaterial.cloud uses the data channel capability of WebRTC, defined by the RTCDataChannel interface. This
      interface allows for bidirectional transfer of peer-to-peer data. The work uses the PeerJS library to
      simplify the process of setting up connections and dealing with messaging. PeerJS provides an API like Socket.io
      to send and receive messages with few lines of code. PeerJS also includes a signaling server which allows a
      programmer to use the library without having to set up and run a server. Though immaterial.cloud uses video as
      it’s main mode of user interaction, the RTCPeerConnection API isn’t used because video isn’t streamed between
      devices.
    </notes>
  </div>

  <div>

    <img src="images/vizInterface.png" alt="">
    <notes>
      immaterial.cloud needs two to four smartphones (iPhone or Android) connected to the internet via WiFi or a
      cellular network. All sound during the installation is played through the phones via a web browser.
      immaterial.cloud will work with a group of participants or just one. A user interacts with immaterial.cloud
      through motion, waving a hand or walking up to a phone. The camera of the phone tracks any change
      in motion, triggers an update to the sound playing, and updates all other phones.
    </notes>
  </div>

  <div>
    <img src="images/setupInterface.png" alt="">
    <notes>
      A participant joins the network by going to https:// immaterial.cloud and entering the ID of a chosen “host”
      phone. Though the “host” phone doesn’t need to enter any ID to play, the participant still needs to press join to
      start the sound. It’s necessary to use IDs so immaterial.cloud knows which phones to send
      messages to (without participants having to sign up for accounts).
    </notes>
  </div>

  <div>
    <img src="images/userInteraction.png" alt="">
    <notes>
      A typical interaction might go as follows. A user waves their hand over a phone, which is assigned a preset of
      “deeper,” then the preset is sent to each of the other phones, first traveling through the server phone to change
      its preset to “deeper”. 
    </notes>
  </div>

  <div>
    <img src="images/technical-overview.png" alt="">
    <notes>
      This diagram shows how data flows from the triggered phone to the server phone,
      then out to the other peer phones, setting the other phones sound to the chosen preset. The user doesn’t have fine
      grained control over how the sounds develope but can explore the different
      presets by triggering each phone.

      Each preset uses one of four granulated samples, a ring tone, a double bass improvisation, a music box, or tubular
      bells. The presets control the pitch, attack, release, and density for each grain of the granular synthesis.
      When a player triggers a new preset, the system interpolates between the previous preset and the new preset over a
      randomly chosen length of time. This combination of presets and interpolation provides different sound
      possibilities without too much chaotic variation.
    </notes>
  </div>

  <div>
    Future Work

    <notes>
      Peer-to-peer technologies provide a pathway to a form of networked communication that doesn’t rely on the
      attention economy. immaterial.cloud is an early step in the movement towards peer-to-peer networked art. 

      While immaterial.cloud uses WebRTC, I think it is important to outline possible future protocols. Many
      technologies are currently in development that seek to invert the current
      client/server architecture of the web. These systems share a vision for a decentralized internet. Some popular
      protocols include Interplanitary File System (IPFS), Secure Scuttlebutt, Hypercore Protocol, and Matrix.

      These protocols vary in design and goals. One could imagine a composer choosing a specific protocol as a
      compositional choice that would make for more interesting modes of interaction for our networked web audio
      creations of the future.
    </notes>
  </div>

  <div id="citations">References</div>

  <div>
    <div>Thank You</div>
    <em> tatecarson@pm.me </em>
    <a href="https://tatecarson.com" target="blank">https://tatecarson.com</a>
  </div>
  <div>

    Slides - <a href="https://wac-2021.netlify.app">https://wac-2021.netlify.app</a>

  </div>

</body>

</html>